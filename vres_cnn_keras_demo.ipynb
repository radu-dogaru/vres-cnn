{
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU",
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Demo for training and using the VRES_CNN model in Keras\n",
        "\n",
        "If useful, please cite the paper:\n",
        "R. Dogaru and Ioana Dogaru, \"VRES-CNN: A Tiny Convolutional Image\n",
        "Classifier with Versatile Choice of Hyperparameters\", in Proceedings ECAI 2024."
      ],
      "metadata": {
        "id": "p7gl-yzOUZZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0 - Load data (some extra-dataset may be required)"
      ],
      "metadata": {
        "id": "loh2IGVALkfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install extra-keras-datasets\n",
        "from extra_keras_datasets import emnist, svhn, stl10\n",
        "# EMNIST may not be functional as of may 27, 2024"
      ],
      "metadata": {
        "id": "t0DmlWqvQ_Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaf4071a-4d9e-42c3-d943-700cd2bdefcc",
        "execution": {
          "iopub.status.busy": "2024-05-27T10:52:29.405857Z",
          "iopub.execute_input": "2024-05-27T10:52:29.406265Z",
          "iopub.status.idle": "2024-05-27T10:52:42.102455Z",
          "shell.execute_reply.started": "2024-05-27T10:52:29.406231Z",
          "shell.execute_reply": "2024-05-27T10:52:42.101412Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: extra-keras-datasets in /opt/conda/lib/python3.10/site-packages (1.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from extra-keras-datasets) (1.26.4)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from extra-keras-datasets) (1.11.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from extra-keras-datasets) (2.1.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from extra-keras-datasets) (1.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->extra-keras-datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->extra-keras-datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->extra-keras-datasets) (2023.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->extra-keras-datasets) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->extra-keras-datasets) (3.2.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->extra-keras-datasets) (1.16.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "datagen=False\n",
        "dataset='cifar10' # mnist or f-mnist or cifar10\n",
        "reduced=0  #  a positive value represents a reduced number of training samples (when memory allocation problems occur)\n",
        "dformat='channels_last'\n",
        "\n",
        "from keras.datasets import mnist, cifar10, cifar100, fashion_mnist\n",
        "\n",
        "\n",
        "if dataset=='mnist':\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "elif  dataset=='cifar10':\n",
        "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "elif  dataset=='cifar100':\n",
        "    (x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "elif dataset=='f-mnist':\n",
        "    (x_train, y_train), (x_test, y_test) =  fashion_mnist.load_data()\n",
        "elif dataset=='emnist':\n",
        "    (x_train, y_train), (x_test, y_test) =  emnist.load_data()\n",
        "elif dataset=='svhn':\n",
        "    (x_train, y_train), (x_test, y_test) =  svhn.load_data()\n",
        "elif dataset=='stl10':\n",
        "    (x_train, y_train), (x_test, y_test) =  stl10.load_data()\n",
        "\n",
        "if (np.ndim(x_train)==3):   # E.g.  MNIST or F-MNIST\n",
        "    x_train=np.reshape(x_train, [np.shape(x_train)[0],np.shape(x_train)[1],np.shape(x_train)[2], 1])\n",
        "    x_test=np.reshape(x_test, [np.shape(x_test)[0],np.shape(x_test)[1],np.shape(x_test)[2], 1] )\n",
        "# place a  1 in the end to keep it compatible with kernel in conv2d\n",
        "# scaling in ([0,1])\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /=255\n",
        "inp_chan=np.shape(x_train)[3]\n",
        "print('Number of input channels in image:', inp_chan)\n",
        "num_classes=int(np.max(y_train)+1)\n",
        "num_inputs = np.shape(x_test)[1]\n",
        "input_shape=np.shape(x_train)[1:4]\n",
        "imsize=input_shape[0]\n",
        "\n",
        "# if reduced >0\n",
        "if reduced>0:\n",
        "    Ntr1=reduced\n",
        "    x_train=x_train[0:Ntr1,:,:,:]\n",
        "    y_train=y_train[0:Ntr1]\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "print('Training samples: ',np.shape(x_train)[0]); print('Validation samples: ',np.shape(x_test)[0]);\n",
        "print('Input data shape : ', np.shape(x_train)[1], 'x', np.shape(x_train)[2] )\n",
        "print('Number of classes: ',num_classes)"
      ],
      "metadata": {
        "id": "yFFIr2Je52eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1478b2-0421-4ff3-fa7b-aa2683bd51c5",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:51:30.891186Z",
          "iopub.execute_input": "2024-05-27T13:51:30.891525Z",
          "iopub.status.idle": "2024-05-27T13:51:54.503411Z",
          "shell.execute_reply.started": "2024-05-27T13:51:30.891495Z",
          "shell.execute_reply": "2024-05-27T13:51:54.502453Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "Number of input channels in image: 3\n",
            "Training samples:  50000\n",
            "Validation samples:  10000\n",
            "Input data shape :  32 x 32\n",
            "Number of classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 -   Define VRES-CNN model (less compact V-CNN included also)\n",
        "For V-CNN detalils: https://github.com/radu-dogaru/V-CNN"
      ],
      "metadata": {
        "id": "kY20uBAHhZEc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model VRES-CNN\n",
        "# Copyright Radu & Ioana Dogaru, May 2024\n",
        "# code in support of paper\n",
        "# R. Dogaru and Ioana Dogaru, \"VRES-CNN: A Tiny Convolutional Image Classifier with Versatile Choice of Hyperparameters\", in Proceedings ECAI 2024.\n",
        "\n",
        "#-----------------------------------------------------------------------\n",
        "import numpy as np\n",
        "from keras.layers import Input, Conv2D, SeparableConv2D, ReLU, BatchNormalization,\\\n",
        "                                    Add, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, \\\n",
        "                                    Flatten, Dense, Dropout, Activation, Identity, Concatenate\n",
        "from keras.models import Model\n",
        "sparse=False # depends on datasets\n",
        "\n",
        "\n",
        "def svcnn_resblock(x, filters, nl, resid=True, separ=True):\n",
        "    # filters and nl regarding macro-block\n",
        "    # csize=3 = economical, 5 gives faster convergence but not so light\n",
        "    csize=3; stri=2; psiz=4; pad='same';\n",
        "    drop1=0.6 # One may try other values e.g. 0.5\n",
        "    if nl>0:\n",
        "        if separ:\n",
        "            y=SeparableConv2D(filters, padding=pad, kernel_size=(csize, csize))(x)\n",
        "        else:\n",
        "            y=Conv2D(filters, padding=pad, kernel_size=(csize, csize))(x)\n",
        "        z=y\n",
        "        y=Activation('relu')(y)\n",
        "        for nonlin in range(1,nl):\n",
        "            if separ:\n",
        "                y=SeparableConv2D(filters, padding=pad, kernel_size=(csize, csize))(y)  # aici era (z) inainte de 5 iul ora 20\n",
        "            else:\n",
        "                y=Conv2D(filters, padding=pad, kernel_size=(csize, csize))(y)  # aici era (z) inainte de 5 iul ora 20\n",
        "            y=Activation('relu')(y)\n",
        "        if separ:\n",
        "            y=SeparableConv2D(filters, padding=pad, kernel_size=(csize, csize))(y)# Activ NL-CNN-2\n",
        "        else:\n",
        "            y=Conv2D(filters, padding=pad, kernel_size=(csize, csize))(y)#\n",
        "    else:\n",
        "        if separ:\n",
        "            y=SeparableConv2D(filters, padding=pad, kernel_size=(csize, csize) )(x)  # Activ NL-CNN-2\n",
        "        else:\n",
        "            y=Conv2D(filters, padding=pad, kernel_size=(csize, csize) )(x)  # Activ NL-CNN-2\n",
        "        z=y\n",
        "\n",
        "    if resid:\n",
        "        out = Add()([z, y])\n",
        "    else:\n",
        "        out=y\n",
        "    out=BatchNormalization()(out)  # Comment if no batch normalization ...\n",
        "    out=MaxPooling2D(pool_size=(psiz, psiz),strides=(stri,stri),padding=pad)(out)\n",
        "    out=Dropout(drop1)(out)   # If missing, very low performance and overfit present.\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "def create_vres_cnn(input_shape, num_classes, flat=1, fil=[100,100,100,100], nl=[1,1,0,0], hid=[], resid=True, separ=True):\n",
        "    # Note the number of elements in fil list (macrolayers) should be the same in nl list\n",
        "    # hid can be [] while if the are elements, additional dense layers are added in the output classifier\n",
        "    my_opt=keras.optimizers.Adam(learning_rate=0.01) # may be changed\n",
        "    nfilmax=np.shape(np.array(fil))[0]\n",
        "\n",
        "    inputs = Input(shape=input_shape) # / 255  # scaling\n",
        "    #============= MODULE MAIN =======================================================\n",
        "    # First macrolayer - connected to input  ----------------\n",
        "    layer=0\n",
        "    #print('layer: ',layer,' nl: ',nl[layer])\n",
        "    t=svcnn_resblock(inputs, fil[layer], nl[layer], resid, separ)\n",
        "    for layer in range(1,nfilmax):\n",
        "        #print('layer: ',layer,' nl: ',nl[layer])\n",
        "        t=svcnn_resblock(t, fil[layer], nl[layer], resid, separ)\n",
        "\n",
        "    # Exit classifier\n",
        "    # INPUT TO DENSE LAYER (FLATTEN - more data can overfit / GLOBAL - less data - may be a good choice )\n",
        "    if flat==1:\n",
        "        t=Flatten()(t)  #\n",
        "    elif flat==0:\n",
        "        t=GlobalAveragePooling2D()(t) #\n",
        "    #=============== END MODULE MAIN - BEGIN MODULE 2 =================\n",
        "\n",
        "    nhid=np.shape(np.array(hid))[0]\n",
        "    if nhid>0:\n",
        "        for lay in range(nhid):\n",
        "            t=Dense(hid[lay], activation='relu')(t)\n",
        "            #model.add(Dropout(drop1))\n",
        "    outputs =Dense(num_classes, activation='softmax')(t)\n",
        "    model = Model(inputs, outputs)\n",
        "# END OF MODEL DESCRIPTION\n",
        "    if sparse:\n",
        "        model.compile(\n",
        "            optimizer=my_opt,\n",
        "            #optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, nesterov=True),\n",
        "            loss = 'sparse_categorical_crossentropy',\n",
        "            metrics=['sparse_categorical_accuracy']\n",
        "            )\n",
        "    else:\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=my_opt,\n",
        "                      metrics=['accuracy'])\n",
        "    model.build(input_shape)\n",
        "    return model"
      ],
      "metadata": {
        "id": "_hNu08onJ8l9",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:51:54.505426Z",
          "iopub.execute_input": "2024-05-27T13:51:54.506122Z",
          "iopub.status.idle": "2024-05-27T13:51:54.526529Z",
          "shell.execute_reply.started": "2024-05-27T13:51:54.506088Z",
          "shell.execute_reply": "2024-05-27T13:51:54.525423Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2  - construct a VRES-CNN model with specific hyper-params."
      ],
      "metadata": {
        "id": "wBHUV3mLJ8l9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "version='VRESCNN' # VRESCNN or VCNN\n",
        "myflat=0; myfil=[80,100,40]; mynl=[2,1,1]; myhid=[]   # aici se pot testa diferite alte valori\n",
        "\n",
        "if version=='VRESCNN':\n",
        "    my_resid=True\n",
        "    my_separ=True\n",
        "elif version == 'VCNN':\n",
        "    my_resid=False\n",
        "    my_separ=False\n",
        "\n",
        "model=create_vres_cnn(input_shape, num_classes, flat=myflat, fil=myfil, nl=mynl, hid=myhid, resid=my_resid, separ=my_separ)\n",
        "model_name=version+'_'+str(myflat)+'_'+str(myfil)+'_'+str(mynl)+'_'+str(myhid)\n",
        "print(model_name)\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9LVn5AKjJ8l9",
        "outputId": "36a99ab6-47d1-41d4-d301-4bd3eeb5dfbb",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:51:59.718850Z",
          "iopub.execute_input": "2024-05-27T13:51:59.719707Z",
          "iopub.status.idle": "2024-05-27T13:52:00.554511Z",
          "shell.execute_reply.started": "2024-05-27T13:51:59.719668Z",
          "shell.execute_reply": "2024-05-27T13:52:00.553560Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VRESCNN_0_[80, 100, 40]_[2, 1, 1]_[]\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " separable_conv2d (Separabl  (None, 32, 32, 80)           347       ['input_1[0][0]']             \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 32, 32, 80)           0         ['separable_conv2d[0][0]']    \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (Separa  (None, 32, 32, 80)           7200      ['activation[0][0]']          \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 32, 32, 80)           0         ['separable_conv2d_1[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (Separa  (None, 32, 32, 80)           7200      ['activation_1[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 32, 32, 80)           0         ['separable_conv2d[0][0]',    \n",
            "                                                                     'separable_conv2d_2[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 32, 32, 80)           320       ['add[0][0]']                 \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 80)           0         ['batch_normalization[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 16, 16, 80)           0         ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (Separa  (None, 16, 16, 100)          8820      ['dropout[0][0]']             \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 16, 16, 100)          0         ['separable_conv2d_3[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (Separa  (None, 16, 16, 100)          11000     ['activation_2[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 16, 16, 100)          0         ['separable_conv2d_3[0][0]',  \n",
            "                                                                     'separable_conv2d_4[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 16, 16, 100)          400       ['add_1[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 100)            0         ['batch_normalization_1[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)         (None, 8, 8, 100)            0         ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (Separa  (None, 8, 8, 40)             4940      ['dropout_1[0][0]']           \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 8, 8, 40)             0         ['separable_conv2d_5[0][0]']  \n",
            "                                                                                                  \n",
            " separable_conv2d_6 (Separa  (None, 8, 8, 40)             2000      ['activation_3[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 8, 8, 40)             0         ['separable_conv2d_5[0][0]',  \n",
            "                                                                     'separable_conv2d_6[0][0]']  \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 8, 8, 40)             160       ['add_2[0][0]']               \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 40)             0         ['batch_normalization_2[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)         (None, 4, 4, 40)             0         ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 40)                   0         ['dropout_2[0][0]']           \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 10)                   410       ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 42797 (167.18 KB)\n",
            "Trainable params: 42357 (165.46 KB)\n",
            "Non-trainable params: 440 (1.72 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare for training - best model (best val_accuracy) saving"
      ],
      "metadata": {
        "id": "zqEskmYzok3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import time as ti\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose=1)"
      ],
      "metadata": {
        "id": "D0TaappDhZEf",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:52:08.358503Z",
          "iopub.execute_input": "2024-05-27T13:52:08.359236Z",
          "iopub.status.idle": "2024-05-27T13:52:08.363977Z",
          "shell.execute_reply.started": "2024-05-27T13:52:08.359200Z",
          "shell.execute_reply": "2024-05-27T13:52:08.363015Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2- Training"
      ],
      "metadata": {
        "id": "ImbNMClXriUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoci=100  # epochs number\n",
        "if datagen==False:\n",
        "    batch_size=100  # batch_size to be defined here\n",
        "import time as ti\n",
        "t1=ti.time()\n",
        "\n",
        "#\n",
        "if datagen:\n",
        "  history = model.fit(train_generator, epochs=epoci, validation_data=validation_generator, verbose=1,\n",
        "                    callbacks = checkpoint)\n",
        "else:\n",
        "  history = model.fit(x_train, y_train, epochs=epoci, validation_data=(x_test, y_test), batch_size=batch_size, verbose=1,\n",
        "                    callbacks = checkpoint)\n",
        "\n",
        "t2=ti.time()\n",
        "print('====================================================')\n",
        "print('Training with  ',epoci,' epochs, lasted  ',int(t2-t1)/60,' minutes')\n",
        "\n",
        "model=load_model('best_model.keras')\n",
        "\n",
        "t1=ti.time()\n",
        "if datagen:\n",
        "    score = model.evaluate(validation_generator, verbose=0)\n",
        "else:\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "t2=ti.time()\n",
        "\n",
        "print('--------------  Report  ------------------------')\n",
        "print ('Model size (K-params): ',model.count_params()//1000)\n",
        "print('Best validation accuracy :', 100*score[1],'%')\n",
        "print ('Prediction time per entire validation set: ',t2-t1)\n",
        "print('Latency (per sample):', 1000*(t2-t1)/np.shape(x_test)[0], 'ms')\n",
        "print('Dataset : ',dataset)\n",
        "print('Model: ',model_name)\n",
        "print('Image size: ',imsize)\n",
        "print('Batch size: ', batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuKMFzTSJ8l-",
        "outputId": "b3ce9e9a-87e1-4b89-a0e5-52f0cc832aee",
        "execution": {
          "iopub.status.busy": "2024-05-27T13:52:13.176596Z",
          "iopub.execute_input": "2024-05-27T13:52:13.177233Z",
          "iopub.status.idle": "2024-05-27T14:00:03.960068Z",
          "shell.execute_reply.started": "2024-05-27T13:52:13.177205Z",
          "shell.execute_reply": "2024-05-27T14:00:03.958966Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 1.5465 - accuracy: 0.4347\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45250, saving model to best_model.keras\n",
            "500/500 [==============================] - 21s 29ms/step - loss: 1.5459 - accuracy: 0.4350 - val_loss: 1.8169 - val_accuracy: 0.4525\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 1.1641 - accuracy: 0.5816\n",
            "Epoch 2: val_accuracy improved from 0.45250 to 0.54210, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 1.1641 - accuracy: 0.5816 - val_loss: 1.3999 - val_accuracy: 0.5421\n",
            "Epoch 3/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 1.0581 - accuracy: 0.6227\n",
            "Epoch 3: val_accuracy improved from 0.54210 to 0.61100, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 1.0577 - accuracy: 0.6228 - val_loss: 1.1737 - val_accuracy: 0.6110\n",
            "Epoch 4/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 1.0001 - accuracy: 0.6404\n",
            "Epoch 4: val_accuracy did not improve from 0.61100\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 1.0000 - accuracy: 0.6404 - val_loss: 1.2124 - val_accuracy: 0.6090\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.9614 - accuracy: 0.6545\n",
            "Epoch 5: val_accuracy improved from 0.61100 to 0.61740, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 29ms/step - loss: 0.9614 - accuracy: 0.6545 - val_loss: 1.1662 - val_accuracy: 0.6174\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.9223 - accuracy: 0.6723\n",
            "Epoch 6: val_accuracy improved from 0.61740 to 0.62360, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.9223 - accuracy: 0.6723 - val_loss: 1.1537 - val_accuracy: 0.6236\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.8918 - accuracy: 0.6863\n",
            "Epoch 7: val_accuracy improved from 0.62360 to 0.68230, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.8918 - accuracy: 0.6863 - val_loss: 0.9311 - val_accuracy: 0.6823\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.8654 - accuracy: 0.6958\n",
            "Epoch 8: val_accuracy did not improve from 0.68230\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.8654 - accuracy: 0.6958 - val_loss: 0.9657 - val_accuracy: 0.6799\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.8400 - accuracy: 0.7047\n",
            "Epoch 9: val_accuracy improved from 0.68230 to 0.72640, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.8400 - accuracy: 0.7047 - val_loss: 0.7899 - val_accuracy: 0.7264\n",
            "Epoch 10/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.8148 - accuracy: 0.7133\n",
            "Epoch 10: val_accuracy did not improve from 0.72640\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.8146 - accuracy: 0.7132 - val_loss: 0.7901 - val_accuracy: 0.7264\n",
            "Epoch 11/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.8009 - accuracy: 0.7188\n",
            "Epoch 11: val_accuracy did not improve from 0.72640\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.8007 - accuracy: 0.7188 - val_loss: 0.9088 - val_accuracy: 0.6915\n",
            "Epoch 12/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.7738 - accuracy: 0.7267\n",
            "Epoch 12: val_accuracy improved from 0.72640 to 0.72850, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7735 - accuracy: 0.7267 - val_loss: 0.7870 - val_accuracy: 0.7285\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.7592 - accuracy: 0.7325\n",
            "Epoch 13: val_accuracy improved from 0.72850 to 0.76470, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7592 - accuracy: 0.7325 - val_loss: 0.7004 - val_accuracy: 0.7647\n",
            "Epoch 14/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.7429 - accuracy: 0.7407\n",
            "Epoch 14: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 15s 29ms/step - loss: 0.7431 - accuracy: 0.7407 - val_loss: 0.8399 - val_accuracy: 0.7038\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.7359 - accuracy: 0.7432\n",
            "Epoch 15: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.7359 - accuracy: 0.7432 - val_loss: 0.8505 - val_accuracy: 0.7185\n",
            "Epoch 16/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.7193 - accuracy: 0.7490\n",
            "Epoch 16: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.7191 - accuracy: 0.7490 - val_loss: 1.0331 - val_accuracy: 0.6778\n",
            "Epoch 17/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.7094 - accuracy: 0.7519\n",
            "Epoch 17: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.7092 - accuracy: 0.7519 - val_loss: 0.7568 - val_accuracy: 0.7454\n",
            "Epoch 18/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.6997 - accuracy: 0.7581\n",
            "Epoch 18: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.6997 - accuracy: 0.7579 - val_loss: 0.7479 - val_accuracy: 0.7517\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6894 - accuracy: 0.7595\n",
            "Epoch 19: val_accuracy did not improve from 0.76470\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6894 - accuracy: 0.7595 - val_loss: 0.7456 - val_accuracy: 0.7410\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.7615\n",
            "Epoch 20: val_accuracy improved from 0.76470 to 0.77780, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.6803 - accuracy: 0.7615 - val_loss: 0.6542 - val_accuracy: 0.7778\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6718 - accuracy: 0.7673\n",
            "Epoch 21: val_accuracy did not improve from 0.77780\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6718 - accuracy: 0.7673 - val_loss: 0.6784 - val_accuracy: 0.7684\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.7691\n",
            "Epoch 22: val_accuracy did not improve from 0.77780\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6647 - accuracy: 0.7691 - val_loss: 0.6507 - val_accuracy: 0.7760\n",
            "Epoch 23/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.6553 - accuracy: 0.7731\n",
            "Epoch 23: val_accuracy did not improve from 0.77780\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6555 - accuracy: 0.7730 - val_loss: 0.6503 - val_accuracy: 0.7715\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6474 - accuracy: 0.7749\n",
            "Epoch 24: val_accuracy did not improve from 0.77780\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.6474 - accuracy: 0.7749 - val_loss: 0.7295 - val_accuracy: 0.7551\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.7727\n",
            "Epoch 25: val_accuracy did not improve from 0.77780\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.6499 - accuracy: 0.7727 - val_loss: 0.6634 - val_accuracy: 0.7660\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6387 - accuracy: 0.7775\n",
            "Epoch 26: val_accuracy improved from 0.77780 to 0.78210, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6387 - accuracy: 0.7775 - val_loss: 0.6322 - val_accuracy: 0.7821\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6303 - accuracy: 0.7809\n",
            "Epoch 27: val_accuracy did not improve from 0.78210\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6303 - accuracy: 0.7809 - val_loss: 0.6624 - val_accuracy: 0.7749\n",
            "Epoch 28/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.6261 - accuracy: 0.7840\n",
            "Epoch 28: val_accuracy did not improve from 0.78210\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.6258 - accuracy: 0.7840 - val_loss: 0.7379 - val_accuracy: 0.7538\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6229 - accuracy: 0.7842\n",
            "Epoch 29: val_accuracy did not improve from 0.78210\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.6229 - accuracy: 0.7842 - val_loss: 0.7628 - val_accuracy: 0.7475\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6162 - accuracy: 0.7870\n",
            "Epoch 30: val_accuracy did not improve from 0.78210\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6162 - accuracy: 0.7870 - val_loss: 0.6851 - val_accuracy: 0.7655\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.6091 - accuracy: 0.7884\n",
            "Epoch 31: val_accuracy improved from 0.78210 to 0.78680, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6091 - accuracy: 0.7884 - val_loss: 0.6240 - val_accuracy: 0.7868\n",
            "Epoch 32/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.6049 - accuracy: 0.7917\n",
            "Epoch 32: val_accuracy did not improve from 0.78680\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6051 - accuracy: 0.7915 - val_loss: 0.7124 - val_accuracy: 0.7713\n",
            "Epoch 33/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.6004 - accuracy: 0.7922\n",
            "Epoch 33: val_accuracy did not improve from 0.78680\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.6005 - accuracy: 0.7921 - val_loss: 0.7076 - val_accuracy: 0.7673\n",
            "Epoch 34/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5933 - accuracy: 0.7945\n",
            "Epoch 34: val_accuracy improved from 0.78680 to 0.79680, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5934 - accuracy: 0.7945 - val_loss: 0.6216 - val_accuracy: 0.7968\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5911 - accuracy: 0.7928\n",
            "Epoch 35: val_accuracy did not improve from 0.79680\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5911 - accuracy: 0.7928 - val_loss: 0.6135 - val_accuracy: 0.7920\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.7963\n",
            "Epoch 36: val_accuracy did not improve from 0.79680\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 0.5897 - accuracy: 0.7963 - val_loss: 0.6379 - val_accuracy: 0.7873\n",
            "Epoch 37/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5852 - accuracy: 0.7993\n",
            "Epoch 37: val_accuracy improved from 0.79680 to 0.81530, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5852 - accuracy: 0.7992 - val_loss: 0.5465 - val_accuracy: 0.8153\n",
            "Epoch 38/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5785 - accuracy: 0.7995\n",
            "Epoch 38: val_accuracy did not improve from 0.81530\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5786 - accuracy: 0.7995 - val_loss: 0.5848 - val_accuracy: 0.8061\n",
            "Epoch 39/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.5775 - accuracy: 0.7996\n",
            "Epoch 39: val_accuracy improved from 0.81530 to 0.81830, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5772 - accuracy: 0.7997 - val_loss: 0.5338 - val_accuracy: 0.8183\n",
            "Epoch 40/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5774 - accuracy: 0.8003\n",
            "Epoch 40: val_accuracy did not improve from 0.81830\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5774 - accuracy: 0.8003 - val_loss: 0.5365 - val_accuracy: 0.8135\n",
            "Epoch 41/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5728 - accuracy: 0.8019\n",
            "Epoch 41: val_accuracy did not improve from 0.81830\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5728 - accuracy: 0.8020 - val_loss: 0.6721 - val_accuracy: 0.7776\n",
            "Epoch 42/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5719 - accuracy: 0.8013\n",
            "Epoch 42: val_accuracy did not improve from 0.81830\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5719 - accuracy: 0.8013 - val_loss: 0.6154 - val_accuracy: 0.7950\n",
            "Epoch 43/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5658 - accuracy: 0.8059\n",
            "Epoch 43: val_accuracy did not improve from 0.81830\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5655 - accuracy: 0.8060 - val_loss: 0.5364 - val_accuracy: 0.8158\n",
            "Epoch 44/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.5626 - accuracy: 0.8046\n",
            "Epoch 44: val_accuracy improved from 0.81830 to 0.82260, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5625 - accuracy: 0.8045 - val_loss: 0.5237 - val_accuracy: 0.8226\n",
            "Epoch 45/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.5603 - accuracy: 0.8044\n",
            "Epoch 45: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5603 - accuracy: 0.8045 - val_loss: 0.5616 - val_accuracy: 0.8096\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5542 - accuracy: 0.8094\n",
            "Epoch 46: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.5542 - accuracy: 0.8094 - val_loss: 0.6726 - val_accuracy: 0.7824\n",
            "Epoch 47/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5506 - accuracy: 0.8071\n",
            "Epoch 47: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5503 - accuracy: 0.8072 - val_loss: 0.5981 - val_accuracy: 0.8038\n",
            "Epoch 48/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5505 - accuracy: 0.8094\n",
            "Epoch 48: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5506 - accuracy: 0.8093 - val_loss: 0.5599 - val_accuracy: 0.8068\n",
            "Epoch 49/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5497 - accuracy: 0.8091\n",
            "Epoch 49: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5498 - accuracy: 0.8091 - val_loss: 0.5314 - val_accuracy: 0.8186\n",
            "Epoch 50/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5426 - accuracy: 0.8128\n",
            "Epoch 50: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5426 - accuracy: 0.8128 - val_loss: 0.5577 - val_accuracy: 0.8154\n",
            "Epoch 51/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5447 - accuracy: 0.8117\n",
            "Epoch 51: val_accuracy did not improve from 0.82260\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.5445 - accuracy: 0.8118 - val_loss: 0.6475 - val_accuracy: 0.7938\n",
            "Epoch 52/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8111\n",
            "Epoch 52: val_accuracy improved from 0.82260 to 0.82570, saving model to best_model.keras\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.5384 - accuracy: 0.8111 - val_loss: 0.5195 - val_accuracy: 0.8257\n",
            "Epoch 53/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.8103\n",
            "Epoch 53: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5417 - accuracy: 0.8103 - val_loss: 0.6420 - val_accuracy: 0.7853\n",
            "Epoch 54/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5392 - accuracy: 0.8110\n",
            "Epoch 54: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5392 - accuracy: 0.8111 - val_loss: 0.5716 - val_accuracy: 0.8080\n",
            "Epoch 55/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5338 - accuracy: 0.8156\n",
            "Epoch 55: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5338 - accuracy: 0.8157 - val_loss: 0.5657 - val_accuracy: 0.8058\n",
            "Epoch 56/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5344 - accuracy: 0.8159\n",
            "Epoch 56: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5344 - accuracy: 0.8159 - val_loss: 0.5251 - val_accuracy: 0.8242\n",
            "Epoch 57/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.8172\n",
            "Epoch 57: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5289 - accuracy: 0.8173 - val_loss: 0.6307 - val_accuracy: 0.7912\n",
            "Epoch 58/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.8185\n",
            "Epoch 58: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.5287 - accuracy: 0.8185 - val_loss: 0.5895 - val_accuracy: 0.8075\n",
            "Epoch 59/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5263 - accuracy: 0.8177\n",
            "Epoch 59: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5262 - accuracy: 0.8176 - val_loss: 0.5415 - val_accuracy: 0.8190\n",
            "Epoch 60/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.8182\n",
            "Epoch 60: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5234 - accuracy: 0.8182 - val_loss: 0.5449 - val_accuracy: 0.8130\n",
            "Epoch 61/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5234 - accuracy: 0.8192\n",
            "Epoch 61: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5234 - accuracy: 0.8192 - val_loss: 0.5322 - val_accuracy: 0.8219\n",
            "Epoch 62/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.8195\n",
            "Epoch 62: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5214 - accuracy: 0.8195 - val_loss: 0.5514 - val_accuracy: 0.8154\n",
            "Epoch 63/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5201 - accuracy: 0.8196\n",
            "Epoch 63: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5200 - accuracy: 0.8195 - val_loss: 0.5369 - val_accuracy: 0.8178\n",
            "Epoch 64/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5147 - accuracy: 0.8208\n",
            "Epoch 64: val_accuracy did not improve from 0.82570\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5146 - accuracy: 0.8208 - val_loss: 0.5259 - val_accuracy: 0.8211\n",
            "Epoch 65/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5165 - accuracy: 0.8215\n",
            "Epoch 65: val_accuracy improved from 0.82570 to 0.82950, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5165 - accuracy: 0.8215 - val_loss: 0.5099 - val_accuracy: 0.8295\n",
            "Epoch 66/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.8220\n",
            "Epoch 66: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5127 - accuracy: 0.8221 - val_loss: 0.5523 - val_accuracy: 0.8188\n",
            "Epoch 67/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.8214\n",
            "Epoch 67: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5093 - accuracy: 0.8214 - val_loss: 0.5213 - val_accuracy: 0.8217\n",
            "Epoch 68/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.8230\n",
            "Epoch 68: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5083 - accuracy: 0.8230 - val_loss: 0.5530 - val_accuracy: 0.8141\n",
            "Epoch 69/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5094 - accuracy: 0.8208\n",
            "Epoch 69: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5094 - accuracy: 0.8208 - val_loss: 0.5619 - val_accuracy: 0.8115\n",
            "Epoch 70/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.8229\n",
            "Epoch 70: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5085 - accuracy: 0.8228 - val_loss: 0.5894 - val_accuracy: 0.8053\n",
            "Epoch 71/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5044 - accuracy: 0.8244\n",
            "Epoch 71: val_accuracy did not improve from 0.82950\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5046 - accuracy: 0.8244 - val_loss: 0.5668 - val_accuracy: 0.8125\n",
            "Epoch 72/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8250\n",
            "Epoch 72: val_accuracy improved from 0.82950 to 0.83980, saving model to best_model.keras\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5059 - accuracy: 0.8250 - val_loss: 0.4837 - val_accuracy: 0.8398\n",
            "Epoch 73/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8234\n",
            "Epoch 73: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.5054 - accuracy: 0.8234 - val_loss: 0.5220 - val_accuracy: 0.8276\n",
            "Epoch 74/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5035 - accuracy: 0.8247\n",
            "Epoch 74: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5035 - accuracy: 0.8247 - val_loss: 0.6233 - val_accuracy: 0.7966\n",
            "Epoch 75/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.8282\n",
            "Epoch 75: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4962 - accuracy: 0.8281 - val_loss: 0.4920 - val_accuracy: 0.8353\n",
            "Epoch 76/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5002 - accuracy: 0.8261\n",
            "Epoch 76: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.5002 - accuracy: 0.8261 - val_loss: 0.6052 - val_accuracy: 0.8026\n",
            "Epoch 77/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4954 - accuracy: 0.8290\n",
            "Epoch 77: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4954 - accuracy: 0.8290 - val_loss: 0.6245 - val_accuracy: 0.7975\n",
            "Epoch 78/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4946 - accuracy: 0.8291\n",
            "Epoch 78: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4942 - accuracy: 0.8292 - val_loss: 0.5741 - val_accuracy: 0.8131\n",
            "Epoch 79/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4964 - accuracy: 0.8284\n",
            "Epoch 79: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4964 - accuracy: 0.8284 - val_loss: 0.5524 - val_accuracy: 0.8178\n",
            "Epoch 80/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4930 - accuracy: 0.8301\n",
            "Epoch 80: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4931 - accuracy: 0.8301 - val_loss: 0.4898 - val_accuracy: 0.8324\n",
            "Epoch 81/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.8278\n",
            "Epoch 81: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4965 - accuracy: 0.8277 - val_loss: 0.4805 - val_accuracy: 0.8332\n",
            "Epoch 82/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4877 - accuracy: 0.8305\n",
            "Epoch 82: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4877 - accuracy: 0.8305 - val_loss: 0.5342 - val_accuracy: 0.8246\n",
            "Epoch 83/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4868 - accuracy: 0.8320\n",
            "Epoch 83: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4868 - accuracy: 0.8320 - val_loss: 0.5284 - val_accuracy: 0.8235\n",
            "Epoch 84/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4875 - accuracy: 0.8306\n",
            "Epoch 84: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4874 - accuracy: 0.8307 - val_loss: 0.5153 - val_accuracy: 0.8264\n",
            "Epoch 85/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.8324\n",
            "Epoch 85: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4845 - accuracy: 0.8324 - val_loss: 0.4875 - val_accuracy: 0.8389\n",
            "Epoch 86/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4853 - accuracy: 0.8316\n",
            "Epoch 86: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4853 - accuracy: 0.8316 - val_loss: 0.5289 - val_accuracy: 0.8291\n",
            "Epoch 87/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.8306\n",
            "Epoch 87: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4863 - accuracy: 0.8307 - val_loss: 0.5944 - val_accuracy: 0.8077\n",
            "Epoch 88/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.8323\n",
            "Epoch 88: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4805 - accuracy: 0.8323 - val_loss: 0.5114 - val_accuracy: 0.8266\n",
            "Epoch 89/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.8336\n",
            "Epoch 89: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 0.4810 - accuracy: 0.8337 - val_loss: 0.5985 - val_accuracy: 0.8053\n",
            "Epoch 90/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4818 - accuracy: 0.8318\n",
            "Epoch 90: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4818 - accuracy: 0.8317 - val_loss: 0.5022 - val_accuracy: 0.8284\n",
            "Epoch 91/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.8340\n",
            "Epoch 91: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4809 - accuracy: 0.8341 - val_loss: 0.5165 - val_accuracy: 0.8274\n",
            "Epoch 92/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.8333\n",
            "Epoch 92: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4807 - accuracy: 0.8333 - val_loss: 0.4828 - val_accuracy: 0.8368\n",
            "Epoch 93/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4723 - accuracy: 0.8364\n",
            "Epoch 93: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4723 - accuracy: 0.8364 - val_loss: 0.5548 - val_accuracy: 0.8168\n",
            "Epoch 94/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.8343\n",
            "Epoch 94: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4756 - accuracy: 0.8343 - val_loss: 0.5840 - val_accuracy: 0.8043\n",
            "Epoch 95/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.8326\n",
            "Epoch 95: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4792 - accuracy: 0.8325 - val_loss: 0.5325 - val_accuracy: 0.8260\n",
            "Epoch 96/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.8347\n",
            "Epoch 96: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4747 - accuracy: 0.8346 - val_loss: 0.5750 - val_accuracy: 0.8116\n",
            "Epoch 97/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.8378\n",
            "Epoch 97: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4746 - accuracy: 0.8378 - val_loss: 0.5513 - val_accuracy: 0.8219\n",
            "Epoch 98/100\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.4721 - accuracy: 0.8363\n",
            "Epoch 98: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4719 - accuracy: 0.8364 - val_loss: 0.4926 - val_accuracy: 0.8363\n",
            "Epoch 99/100\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.8374\n",
            "Epoch 99: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 14s 28ms/step - loss: 0.4683 - accuracy: 0.8374 - val_loss: 0.5709 - val_accuracy: 0.8102\n",
            "Epoch 100/100\n",
            "498/500 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.8348\n",
            "Epoch 100: val_accuracy did not improve from 0.83980\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.4729 - accuracy: 0.8348 - val_loss: 0.5437 - val_accuracy: 0.8201\n",
            "====================================================\n",
            "Training with   100  epochs, lasted   23.466666666666665  minutes\n",
            "--------------  Report  ------------------------\n",
            "Model size (K-params):  42\n",
            "Best validation accuracy : 83.98000001907349 %\n",
            "Prediction time per entire validation set:  3.2602853775024414\n",
            "Latency (per sample): 0.32602853775024415 ms\n",
            "Dataset :  cifar10\n",
            "Model:  VRESCNN_0_[80, 100, 40]_[2, 1, 1]_[]\n",
            "Image size:  32\n",
            "Batch size:  100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display training graphs"
      ],
      "metadata": {
        "id": "Rc1AbXXwmQPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "    if subplot%10==1: # set up the subplots on the first call\n",
        "        plt.subplots(figsize=(7,3), facecolor='#F0F0F0')\n",
        "        plt.tight_layout()\n",
        "    ax = plt.subplot(subplot)\n",
        "    ax.set_facecolor('#F8F8F8')\n",
        "    ax.plot(training)\n",
        "    ax.plot(validation)\n",
        "    ax.set_title('model '+ title)\n",
        "    ax.set_ylabel(title)\n",
        "    #ax.set_ylim(0.28,1.05)\n",
        "    ax.set_xlabel('epoch')\n",
        "    ax.legend(['train', 'valid.'])\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'loss', 121)\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'accuracy', 122)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "45_UlH9tHH1E",
        "outputId": "25ef2374-6d96-4f0b-d2bc-2b5eb3b4f8f5",
        "execution": {
          "iopub.status.busy": "2024-05-27T14:04:14.416481Z",
          "iopub.execute_input": "2024-05-27T14:04:14.417223Z",
          "iopub.status.idle": "2024-05-27T14:04:15.043249Z",
          "shell.execute_reply.started": "2024-05-27T14:04:14.417188Z",
          "shell.execute_reply": "2024-05-27T14:04:15.042375Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-951775051a26>:6: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
            "  ax = plt.subplot(subplot)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "#-----------------------------------------------------------\n",
        "\n",
        "model.save('myname.keras')  # use your favourite name"
      ],
      "metadata": {
        "id": "7n4z2_eh_9QV",
        "execution": {
          "iopub.status.busy": "2024-05-27T11:49:38.222121Z",
          "iopub.execute_input": "2024-05-27T11:49:38.222879Z",
          "iopub.status.idle": "2024-05-27T11:49:38.308855Z",
          "shell.execute_reply.started": "2024-05-27T11:49:38.222847Z",
          "shell.execute_reply": "2024-05-27T11:49:38.307879Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conversion to tflite  (only in Keras 2.x)"
      ],
      "metadata": {
        "id": "DbAQqLFlRZ0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if keras.__version__[0]=='2':\n",
        "    import tensorflow as tf\n",
        "    converter=tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.post_training_quantize=True  #\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model=converter.convert()\n",
        "    myname='tflite_xx'\n",
        "    open(myname,'wb').write(tflite_model)\n",
        "elif keras.__version__[0]=='3':\n",
        "    print('On this platform Keras 3 is installed ; Do restart and !pip install keras==2.15.0')"
      ],
      "metadata": {
        "id": "CDEcZluIO8gx",
        "execution": {
          "iopub.status.busy": "2024-05-27T11:49:40.541579Z",
          "iopub.execute_input": "2024-05-27T11:49:40.541977Z",
          "iopub.status.idle": "2024-05-27T11:49:40.548980Z",
          "shell.execute_reply.started": "2024-05-27T11:49:40.541944Z",
          "shell.execute_reply": "2024-05-27T11:49:40.547902Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh | awk '{print $5 \"\\t\" $9}'"
      ],
      "metadata": {
        "id": "-Rz2eo1e3u1t",
        "outputId": "cea2df4a-627d-4b42-9835-49615c861dfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\n",
            "607K\tbest_model.keras\n",
            "4.0K\tsample_data\n",
            "77K\ttflite_xx\n"
          ]
        }
      ]
    }
  ]
}
